{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations==0.4.5\n",
      "  Using cached albumentations-0.4.5.tar.gz (116 kB)\n",
      "Collecting attrs==19.3.0\n",
      "  Using cached attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting backcall==0.1.0\n",
      "  Using cached backcall-0.1.0.zip (11 kB)\n",
      "Collecting bleach==3.1.4\n",
      "  Using cached bleach-3.1.4-py2.py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: decorator==4.4.2 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 6)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: entrypoints==0.3 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 8)) (0.3)\n",
      "Collecting imageio==2.8.0\n",
      "  Using cached imageio-2.8.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting imgaug==0.2.6\n",
      "  Using cached imgaug-0.2.6.tar.gz (631 kB)\n",
      "Collecting importlib-metadata==1.6.0\n",
      "  Using cached importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ipykernel==5.2.0\n",
      "  Downloading ipykernel-5.2.0-py3-none-any.whl (117 kB)\n",
      "Collecting ipython==7.13.0\n",
      "  Downloading ipython-7.13.0-py3-none-any.whl (780 kB)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 15)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==7.5.1 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 16)) (7.5.1)\n",
      "Collecting jedi==0.16.0\n",
      "  Downloading jedi-0.16.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting Jinja2==2.11.1\n",
      "  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)\n",
      "Collecting joblib==0.14.1\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 20)) (3.2.0)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 21)) (1.0.0)\n",
      "Collecting jupyter-client==6.1.2\n",
      "  Downloading jupyter_client-6.1.2-py3-none-any.whl (106 kB)\n",
      "Collecting jupyter-console==6.1.0\n",
      "  Downloading jupyter_console-6.1.0-py2.py3-none-any.whl (21 kB)\n",
      "Collecting jupyter-core==4.6.3\n",
      "  Downloading jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
      "Collecting kiwisolver==1.2.0\n",
      "  Downloading kiwisolver-1.2.0-cp37-none-win_amd64.whl (57 kB)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 26)) (1.1.1)\n",
      "Collecting matplotlib==3.2.1\n",
      "  Downloading matplotlib-3.2.1-cp37-cp37m-win_amd64.whl (9.2 MB)\n",
      "Requirement already satisfied: mistune==0.8.4 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 28)) (0.8.4)\n",
      "Collecting nbconvert==5.6.1\n",
      "  Downloading nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\n",
      "Collecting nbformat==5.0.5\n",
      "  Downloading nbformat-5.0.5-py3-none-any.whl (170 kB)\n",
      "Collecting networkx==2.4\n",
      "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "Collecting notebook==6.0.3\n",
      "  Downloading notebook-6.0.3-py3-none-any.whl (9.7 MB)\n",
      "Collecting numpy==1.18.2\n",
      "  Downloading numpy-1.18.2-cp37-cp37m-win_amd64.whl (12.8 MB)\n",
      "Collecting opencv-python-headless==4.2.0.34Note: you may need to restart the kernel to use updated packages.\n",
      "  Downloading opencv_python_headless-4.2.0.34-cp37-cp37m-win_amd64.whl (33.0 MB)\n",
      "Collecting pandocfilters==1.4.2\n",
      "  Downloading pandocfilters-1.4.2.tar.gz (14 kB)\n",
      "Collecting parso==0.6.2\n",
      "  Downloading parso-0.6.2-py2.py3-none-any.whl (97 kB)\n",
      "Collecting pexpect==4.8.0\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 38)) (0.7.5)\n",
      "Collecting Pillow==7.1.1\n",
      "  Downloading Pillow-7.1.1-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Collecting prometheus-client==0.7.1\n",
      "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
      "Collecting prompt-toolkit==3.0.5\n",
      "  Downloading prompt_toolkit-3.0.5-py3-none-any.whl (351 kB)\n",
      "Collecting ptyprocess==0.6.0\n",
      "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting Pygments==2.6.1\n",
      "  Downloading Pygments-2.6.1-py3-none-any.whl (914 kB)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 44)) (2.4.7)\n",
      "Collecting pyrsistent==0.16.0\n",
      "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 46)) (2.8.1)\n",
      "Requirement already satisfied: PyWavelets==1.1.1 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 47)) (1.1.1)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 48)) (5.3.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.4.0\n",
      "ERROR: No matching distribution found for torch==1.4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyzmq==19.0.0\n",
      "  Downloading pyzmq-19.0.0-cp37-cp37m-win_amd64.whl (1.1 MB)\n",
      "Collecting qtconsole==4.7.2\n",
      "  Downloading qtconsole-4.7.2-py2.py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: QtPy==1.9.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 51)) (1.9.0)\n",
      "Collecting scikit-image==0.16.2\n",
      "  Downloading scikit_image-0.16.2-cp37-cp37m-win_amd64.whl (25.7 MB)\n",
      "Collecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-win_amd64.whl (6.5 MB)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 55)) (1.5.0)\n",
      "Collecting six==1.14.0\n",
      "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting terminado==0.8.3\n",
      "  Downloading terminado-0.8.3-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: testpath==0.4.4 in c:\\users\\user\\anaconda3\\envs\\sve\\lib\\site-packages (from -r requirements.txt (line 58)) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args :  Namespace(batch_size=4, colorjitter_factor=0.3, copyblob=False, crop_size=[768, 768], cutmix=False, dataset_mean=[0.485, 0.456, 0.406], dataset_path='./minicity', dataset_std=[0.229, 0.224, 0.225], epochs=200, focal_gamma=2.0, hflip=True, loss='ce', lr_init=0.01, lr_momentum=0.9, lr_weight_decay=0.0001, model='DeepLabv3_resnet50', mst=False, norm='batch', num_workers=8, pin_memory=True, predict=False, save_path='./baseline_run', seed=None, test_size=[1024, 2048], train_size=[1024, 2048], weights=None)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './minicity\\\\leftImg8bit\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1a391d094293>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-1a391d094293>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mDataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMiniCity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\github\\2021-02-09\\semantic-segmentation-tutorial-pytorch-master\\learning\\utils.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[1;34m(dataset, args)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[0mvalset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\github\\2021-02-09\\semantic-segmentation-tutorial-pytorch-master\\learning\\minicity.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, split, transform, target_transform, transforms)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Unknown value {} for argument split.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './minicity\\\\leftImg8bit\\\\train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from option import get_args\n",
    "from learning.minicity import MiniCity\n",
    "from learning.learner import train_epoch, validate_epoch, predict\n",
    "from learning.utils import get_dataloader, get_lossfunc, get_model\n",
    "\n",
    "from helpers.helpers import plot_learning_curves\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "def main(): \n",
    "    args = get_args()\n",
    "    #args = parser.parse_args(args=[])\n",
    "    print(\"args : \", args)\n",
    "\n",
    "    # Fix seed\n",
    "    if args.seed is not None:\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting from checkpoints.')\n",
    "\n",
    "    assert args.crop_size[0] <= args.train_size[0] and args.crop_size[1] <= args.train_size[1], \\\n",
    "    'Must be Crop size <= Image Size.'\n",
    "    \n",
    "    # Create directory to store run files\n",
    "    if not os.path.isdir(args.save_path):\n",
    "        os.makedirs(args.save_path + '/images')\n",
    "    if not os.path.isdir(args.save_path + '/results_color_val'):\n",
    "        os.makedirs(args.save_path + '/results_color_val')\n",
    "        os.makedirs(args.save_path + '/results_color_test')\n",
    "    \n",
    "    Dataset = MiniCity\n",
    "\n",
    "    dataloaders = get_dataloader(Dataset, args)\n",
    "    criterion = get_lossfunc(Dataset, args)\n",
    "    model = get_model(Dataset, args)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_init, momentum=args.lr_momentum, weight_decay=args.lr_weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    best_miou = 0.0\n",
    "    metrics = {'train_loss' : [],\n",
    "               'train_acc' : [],\n",
    "               'val_acc' : [],\n",
    "               'val_loss' : [],\n",
    "               'miou' : []}\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Resume training from checkpoint\n",
    "    if args.weights:\n",
    "        print('Resuming training from {}.'.format(args.weights))\n",
    "        checkpoint = torch.load(args.weights)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        metrics = checkpoint['metrics']\n",
    "        best_miou = checkpoint['best_miou']\n",
    "        start_epoch = checkpoint['epoch']+1\n",
    "    \n",
    "    # Push model to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(torch.cuda.device_count(), torch.cuda.get_device_name(0)))\n",
    "\n",
    "    # No training, only running prediction on test set\n",
    "    if args.predict:\n",
    "        checkpoint = torch.load(args.save_path + '/best_weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print('Loaded model weights from {}'.format(args.save_path + '/best_weights.pth.tar'))\n",
    "        # Create results directory\n",
    "        if not os.path.isdir(args.save_path + '/results_val'):\n",
    "            os.makedirs(args.save_path + '/results_val')\n",
    "        if not os.path.isdir(args.save_path + '/results_test'):\n",
    "            os.makedirs(args.save_path + '/results_test')\n",
    "\n",
    "        predict(dataloaders['test'], model, Dataset.mask_colors, folder=args.save_path, mode='test', args=args)\n",
    "        predict(dataloaders['val'], model, Dataset.mask_colors, folder=args.save_path, mode='val', args=args)\n",
    "        return\n",
    "    \n",
    "    # Generate log file\n",
    "    with open(args.save_path + '/log_epoch.csv', 'a') as epoch_log:\n",
    "        epoch_log.write('epoch, train loss, val loss, train acc, val acc, miou\\n')\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        # Train\n",
    "        print('--- Training ---')\n",
    "        train_loss, train_acc = train_epoch(dataloaders['train'], model, criterion, optimizer, scheduler, epoch, void=Dataset.voidClass, args=args)\n",
    "        metrics['train_loss'].append(train_loss)\n",
    "        metrics['train_acc'].append(train_acc)\n",
    "        print('Epoch {} train loss: {:.4f}, acc: {:.4f}'.format(epoch,train_loss,train_acc))\n",
    "        \n",
    "        # Validate\n",
    "        print('--- Validation ---')\n",
    "        val_acc, val_loss, miou = validate_epoch(dataloaders['val'], model, criterion, epoch,\n",
    "                                                 Dataset.classLabels, Dataset.validClasses, void=Dataset.voidClass,\n",
    "                                                 maskColors=Dataset.mask_colors, folder=args.save_path, args=args)\n",
    "        metrics['val_acc'].append(val_acc)\n",
    "        metrics['val_loss'].append(val_loss)\n",
    "        metrics['miou'].append(miou)\n",
    "        \n",
    "        # Write logs\n",
    "        with open(args.save_path + '/log_epoch.csv', 'a') as epoch_log:\n",
    "            epoch_log.write('{}, {:.5f}, {:.5f}, {:.5f}, {:.5f}, {:.5f}\\n'.format(\n",
    "                    epoch, train_loss, val_loss, train_acc, val_acc, miou))\n",
    "        \n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_miou': best_miou,\n",
    "            'metrics': metrics,\n",
    "            }, args.save_path + '/checkpoint.pth.tar')\n",
    "        \n",
    "        # Save best model to file\n",
    "        if miou > best_miou:\n",
    "            print('mIoU improved from {:.4f} to {:.4f}.'.format(best_miou, miou))\n",
    "            best_miou = miou\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                }, args.save_path + '/best_weights.pth.tar')\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    plot_learning_curves(metrics, args)\n",
    "\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(args.save_path + '/best_weights.pth.tar')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    print('Loaded best model weights (epoch {}) from {}/best_weights.pth.tar'.format(checkpoint['epoch'], args.save_path))\n",
    "    \n",
    "    # Create results directory\n",
    "    if not os.path.isdir(args.save_path + '/results_val'):\n",
    "        os.makedirs(args.save_path + '/results_val')\n",
    "\n",
    "    if not os.path.isdir(args.save_path + '/results_test'):\n",
    "        os.makedirs(args.save_path + '/results_test')\n",
    "\n",
    "    # Run prediction on validation set. For predicting on test set, simple replace 'val' by 'test'\n",
    "    predict(dataloaders['val'], model, Dataset.mask_colors, folder=args.save_path, mode='val', args=args)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WinError 3] 지정된 경로를 찾을 수 없습니다:\n",
    "->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\git\\github\\2021-02-09\\semantic-segmentation-tutorial-pytorch-master\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
