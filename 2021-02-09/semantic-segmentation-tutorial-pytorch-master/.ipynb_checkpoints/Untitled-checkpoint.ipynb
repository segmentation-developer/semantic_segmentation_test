{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--model [UNet, DeepLabv3_resnet50, DeepLabv3_resnet101]]\n",
      "                             [--save_path path/to/save_results]\n",
      "                             [--weights path/to/checkpoint]\n",
      "                             [--norm [batch, instance, evo, group]]\n",
      "                             [--dataset_path path/to/minicity/root]\n",
      "                             [--pin_memory [True,False]] [--num_workers 8]\n",
      "                             [--colorjitter_factor 0.3] [--hflip [True,False]]\n",
      "                             [--crop_size CROP_SIZE [CROP_SIZE ...]]\n",
      "                             [--train_size TRAIN_SIZE [TRAIN_SIZE ...]]\n",
      "                             [--test_size TEST_SIZE [TEST_SIZE ...]]\n",
      "                             [--dataset_mean [0.485, 0.456, 0.406]]\n",
      "                             [--dataset_std [0.229, 0.224, 0.225]]\n",
      "                             [--batch_size BATCH_SIZE] [--lr_init 1e-2]\n",
      "                             [--lr_momentum 0.9] [--lr_weight_decay 1e-4]\n",
      "                             [--epochs 200] [--seed 42]\n",
      "                             [--loss [ce, weighted_ce, focal]]\n",
      "                             [--focal_gamma FOCAL_GAMMA] [--cutmix]\n",
      "                             [--copyblob] [--predict] [--mst]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-1e80c37d-8501-463c-a3a3-4025ff00673d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from option import get_args\n",
    "from learning.minicity import MiniCity\n",
    "from learning.learner import train_epoch, validate_epoch, predict\n",
    "from learning.utils import get_dataloader, get_lossfunc, get_model\n",
    "\n",
    "from helpers.helpers import plot_learning_curves\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "def main(): \n",
    "    args = get_args()\n",
    "    #args = parser.parse_args(args=[])\n",
    "    print(\"args : \", args)\n",
    "\n",
    "    # Fix seed\n",
    "    if args.seed is not None:\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting from checkpoints.')\n",
    "\n",
    "    assert args.crop_size[0] <= args.train_size[0] and args.crop_size[1] <= args.train_size[1], \\\n",
    "    'Must be Crop size <= Image Size.'\n",
    "    \n",
    "    # Create directory to store run files\n",
    "    if not os.path.isdir(args.save_path):\n",
    "        os.makedirs(args.save_path + '/images')\n",
    "    if not os.path.isdir(args.save_path + '/results_color_val'):\n",
    "        os.makedirs(args.save_path + '/results_color_val')\n",
    "        os.makedirs(args.save_path + '/results_color_test')\n",
    "    \n",
    "    Dataset = MiniCity\n",
    "\n",
    "    dataloaders = get_dataloader(Dataset, args)\n",
    "    criterion = get_lossfunc(Dataset, args)\n",
    "    model = get_model(Dataset, args)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_init, momentum=args.lr_momentum, weight_decay=args.lr_weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    best_miou = 0.0\n",
    "    metrics = {'train_loss' : [],\n",
    "               'train_acc' : [],\n",
    "               'val_acc' : [],\n",
    "               'val_loss' : [],\n",
    "               'miou' : []}\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Resume training from checkpoint\n",
    "    if args.weights:\n",
    "        print('Resuming training from {}.'.format(args.weights))\n",
    "        checkpoint = torch.load(args.weights)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        metrics = checkpoint['metrics']\n",
    "        best_miou = checkpoint['best_miou']\n",
    "        start_epoch = checkpoint['epoch']+1\n",
    "    \n",
    "    # Push model to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(torch.cuda.device_count(), torch.cuda.get_device_name(0)))\n",
    "\n",
    "    # No training, only running prediction on test set\n",
    "    if args.predict:\n",
    "        checkpoint = torch.load(args.save_path + '/best_weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "        print('Loaded model weights from {}'.format(args.save_path + '/best_weights.pth.tar'))\n",
    "        # Create results directory\n",
    "        if not os.path.isdir(args.save_path + '/results_val'):\n",
    "            os.makedirs(args.save_path + '/results_val')\n",
    "        if not os.path.isdir(args.save_path + '/results_test'):\n",
    "            os.makedirs(args.save_path + '/results_test')\n",
    "\n",
    "        predict(dataloaders['test'], model, Dataset.mask_colors, folder=args.save_path, mode='test', args=args)\n",
    "        predict(dataloaders['val'], model, Dataset.mask_colors, folder=args.save_path, mode='val', args=args)\n",
    "        return\n",
    "    \n",
    "    # Generate log file\n",
    "    with open(args.save_path + '/log_epoch.csv', 'a') as epoch_log:\n",
    "        epoch_log.write('epoch, train loss, val loss, train acc, val acc, miou\\n')\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        # Train\n",
    "        print('--- Training ---')\n",
    "        train_loss, train_acc = train_epoch(dataloaders['train'], model, criterion, optimizer, scheduler, epoch, void=Dataset.voidClass, args=args)\n",
    "        metrics['train_loss'].append(train_loss)\n",
    "        metrics['train_acc'].append(train_acc)\n",
    "        print('Epoch {} train loss: {:.4f}, acc: {:.4f}'.format(epoch,train_loss,train_acc))\n",
    "        \n",
    "        # Validate\n",
    "        print('--- Validation ---')\n",
    "        val_acc, val_loss, miou = validate_epoch(dataloaders['val'], model, criterion, epoch,\n",
    "                                                 Dataset.classLabels, Dataset.validClasses, void=Dataset.voidClass,\n",
    "                                                 maskColors=Dataset.mask_colors, folder=args.save_path, args=args)\n",
    "        metrics['val_acc'].append(val_acc)\n",
    "        metrics['val_loss'].append(val_loss)\n",
    "        metrics['miou'].append(miou)\n",
    "        \n",
    "        # Write logs\n",
    "        with open(args.save_path + '/log_epoch.csv', 'a') as epoch_log:\n",
    "            epoch_log.write('{}, {:.5f}, {:.5f}, {:.5f}, {:.5f}, {:.5f}\\n'.format(\n",
    "                    epoch, train_loss, val_loss, train_acc, val_acc, miou))\n",
    "        \n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_miou': best_miou,\n",
    "            'metrics': metrics,\n",
    "            }, args.save_path + '/checkpoint.pth.tar')\n",
    "        \n",
    "        # Save best model to file\n",
    "        if miou > best_miou:\n",
    "            print('mIoU improved from {:.4f} to {:.4f}.'.format(best_miou, miou))\n",
    "            best_miou = miou\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                }, args.save_path + '/best_weights.pth.tar')\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    plot_learning_curves(metrics, args)\n",
    "\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(args.save_path + '/best_weights.pth.tar')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    print('Loaded best model weights (epoch {}) from {}/best_weights.pth.tar'.format(checkpoint['epoch'], args.save_path))\n",
    "    \n",
    "    # Create results directory\n",
    "    if not os.path.isdir(args.save_path + '/results_val'):\n",
    "        os.makedirs(args.save_path + '/results_val')\n",
    "\n",
    "    if not os.path.isdir(args.save_path + '/results_test'):\n",
    "        os.makedirs(args.save_path + '/results_test')\n",
    "\n",
    "    # Run prediction on validation set. For predicting on test set, simple replace 'val' by 'test'\n",
    "    predict(dataloaders['val'], model, Dataset.mask_colors, folder=args.save_path, mode='val', args=args)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
